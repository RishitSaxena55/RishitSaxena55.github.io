<!DOCTYPE html>
<html>

<head>
    <style>
        body {
            font-family: Arial, sans-serif;
            font-size: 11pt;
            color: #000;
            line-height: 1.6;
            max-width: 750px;
        }

        p {
            margin-bottom: 1em;
        }

        a {
            color: #1155cc;
            text-decoration: underline;
        }

        .subject {
            font-weight: bold;
            margin-bottom: 20px;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }

        .highlight {
            background: #fef3c7;
            padding: 12px;
            border-left: 4px solid #f59e0b;
            margin: 15px 0;
        }

        .divider {
            border: none;
            border-top: 1px solid #eee;
            margin: 20px 0;
        }

        table {
            border-collapse: collapse;
            width: 100%;
            margin: 15px 0;
        }

        th,
        td {
            border: 1px solid #ddd;
            text-align: left;
            padding: 10px;
            vertical-align: top;
        }

        th {
            background: #f8f9fa;
        }
    </style>
</head>

<body>

    <div class="subject">
        <strong>To:</strong> hichristensen@ucsd.edu<br><br>
        <strong>Subject:</strong> Summer Research: Deep Learning Systems for Vision — IIIT Guwahati
    </div>

    <p>Dear Professor Christensen,</p>

    <p>I am <strong>Rishit Saxena</strong>, a second-year CS student at <strong>IIIT Guwahati</strong>, India (CPI:
        9.23/10). Your leadership in <strong>robot systems</strong> and the <strong>Contextual Robotics
            Institute</strong> — along with your systems-level approach to autonomy — inspires me to apply for a summer
        research position. While my background is in neural 3D representations (NeRF, 3D Gaussian Splatting), I've
        built deep learning systems from first principles, which aligns with your emphasis on <strong>robust systems
            engineering</strong>.</p>

    <p>I am writing to explore opportunities in CRI for <strong>Summer 2026 (May–August)</strong>.</p>

    <hr class="divider">

    <div class="highlight">
        <strong>Why I'm Reaching Out:</strong><br>
        Your recent CORL 2025 paper on <strong>"Merging and Disentangling Views in Visual Reinforcement Learning for
            Robotic Manipulation"</strong> caught my attention — the intersection of visual representation learning and
        robot control. My experience implementing 3D scene representations (NeRF, 3DGS) and building a deep learning
        framework from scratch (TorchiFy) has given me strong foundations in both <strong>visual understanding</strong>
        and <strong>systems-level thinking</strong>. I'm eager to apply these skills to robot systems challenges.
    </div>

    <p><strong>My Relevant Experience:</strong></p>

    <table>
        <tr>
            <th style="width: 25%;">Project</th>
            <th>What I Built</th>
            <th>Systems Relevance</th>
        </tr>
        <tr>
            <td><strong><a href="https://github.com/RishitSaxena55/TorchiFy-v1">TorchiFy</a></strong></td>
            <td>PyTorch-like DL framework from scratch: <strong>Autograd engine</strong>, Multi-Head Attention,
                LayerNorm with custom backward passes</td>
            <td><strong>Systems-level understanding of ML infrastructure</strong></td>
        </tr>
        <tr>
            <td><strong><a href="https://github.com/RishitSaxena55/gaussian-splatting-pytorch">3D Gaussian
                        Splatting</a></strong></td>
            <td>Complete differentiable rasterizer: SfM initialization, Spherical Harmonics, custom backward passes
            </td>
            <td><strong>3D scene representation for robot perception</strong></td>
        </tr>
        <tr>
            <td><strong><a href="https://github.com/RishitSaxena55/NeRF-PyTorch-">NeRF</a></strong></td>
            <td>Pure PyTorch implementation: positional encoding, volume rendering</td>
            <td><strong>Visual scene understanding</strong></td>
        </tr>
        <tr>
            <td><strong><a href="https://github.com/RishitSaxena55/EENet">EENet</a></strong></td>
            <td>Early Exit Networks reducing inference latency by 40%</td>
            <td><strong>Efficient inference for real-time robotics</strong></td>
        </tr>
    </table>

    <p><strong>What Excites Me About CRI:</strong></p>
    <ul>
        <li><strong>Systems approach to robotics</strong> — holistic view of perception, planning, and control</li>
        <li><strong>Visual RL for Manipulation</strong> — bridging vision and robot learning</li>
        <li><strong>Autonomous Vehicle Laboratory</strong> — real-world deployment challenges</li>
        <li><strong>US National Robotics Roadmap</strong> — shaping the future of the field</li>
    </ul>

    <p><strong>Links:</strong> <a href="https://rishitsaxena55.github.io">Portfolio</a> | <a
            href="https://github.com/RishitSaxena55">GitHub</a> | <a
            href="https://linkedin.com/in/rishit-saxena-12922531b">LinkedIn</a></p>

    <p>Thank you for your time. I recognize my background is more vision-focused than systems-focused, but my
        experience building ML infrastructure from scratch demonstrates the systems thinking I would bring to CRI.</p>

    <p>Best regards,<br>
        <strong>Rishit Saxena</strong><br>
        rishitsaxena55@gmail.com | +91 7082968644
    </p>

</body>

</html>