<!DOCTYPE html>
<html>

<head>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 20px auto;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 8px;
            background-color: #f9f9f9;
        }

        .header {
            border-bottom: 2px solid #ea580c;
            padding-bottom: 10px;
            margin-bottom: 20px;
        }

        /* Orange accent for Princeton? Or back to blue */
        .subject {
            font-weight: bold;
            font-size: 1.2em;
            color: #1f2937;
            margin-bottom: 15px;
        }

        .content {
            background: white;
            padding: 30px;
            border-radius: 6px;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        a {
            color: #ea580c;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }
    </style>
</head>

<body>
    <div class="header">
        <p><strong>To:</strong> fheide@cs.princeton.edu</p>
        <p><strong>From:</strong> rishitsaxena55@gmail.com</p>
    </div>

    <div class="content">
        <div class="subject">Subject: Inquiry from Researcher: Differentiable Rendering & Neural Fields (Re: Neural
            Atlas Graphs)</div>

        <p>Dear Professor Heide,</p>

        <p>I recently read your NeurIPS 2025 Spotlight paper, <strong>"Neural Atlas Graphs for Dynamic Scene
                Decomposition and Editing"</strong>, and was fascinated by how it tackles the decomposition of dynamic
            scenes—a critical next step for manageable neural representations.</p>

        <p>I am an undergraduate researcher passionate about <strong>computational imaging and neural
                rendering</strong>. I have focused on building differentiable rendering pipelines from first principles,
            including implementing a <strong>3D Gaussian Splatting rasterizer from scratch in PyTorch</strong> (handling
            adaptive density control and spherical harmonics) and a <strong>NeRF volume rendering engine</strong>. My
            goal has been to deeply understand the gradient flow and physical priors required for synthesizing
            photo-realistic views.</p>

        <p>My background also includes optimizing these representations for efficiency (via my work on Early Exit
            Networks), which I believe aligns well with your lab’s work on efficient and novel scene representations
            (like Neural Spline Fields and Radar Fields). I am writing to inquire if you are accepting research interns
            for Summer 2025 to work on next-generation neural rendering or computational imaging problems.</p>

        <p>I have attached my resume and linked my portfolio below.</p>

        <p>Best regards,<br>
            Rishit Saxena<br>
            <a href="https://rishitsaxena55.github.io">Portfolio</a> | <a
                href="https://github.com/RishitSaxena55">GitHub</a>
        </p>
    </div>
</body>

</html>
