<!DOCTYPE html>
<html>

<head>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 20px auto;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 8px;
            background-color: #f9f9f9;
        }

        .header {
            border-bottom: 2px solid #2563eb;
            padding-bottom: 10px;
            margin-bottom: 20px;
        }

        .subject {
            font-weight: bold;
            font-size: 1.2em;
            color: #1f2937;
            margin-bottom: 15px;
        }

        .content {
            background: white;
            padding: 30px;
            border-radius: 6px;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .highlight {
            background-color: #fff3cd;
            padding: 0 2px;
        }

        a {
            color: #2563eb;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }
    </style>
</head>

<body>
    <div class="header">
        <p><strong>To:</strong> yongjaelee@cs.wisc.edu</p>
        <p><strong>From:</strong> rishitsaxena55@gmail.com</p>
    </div>

    <div class="content">
        <div class="subject">Subject: Inquiry from Researcher implementing 3DGS Pruning/Optimization (Re: Lp-3DGS)</div>

        <p>Dear Professor Lee,</p>

        <p>I recently read your paper <strong>"Lp-3DGS: Learning to Prune 3D Gaussian Splatting"</strong> (NeurIPS 2025)
            and was particularly inspired by your approach to reducing primitive counts while maintaining rendering
            fidelity. The challenge of balancing memory efficiency with scene quality is something I’ve encountered
            directly in my own work.</p>

        <p>I am a computer science undergraduate researcher deeply focused on <strong>efficient computer
                vision</strong>. I have built a <strong>differentiable 3D Gaussian Splatting rasterizer from scratch in
                PyTorch</strong>, where I implemented adaptive density control strategies (cloning, splitting, and
            pruning) to scale scenes from 50K to 300K+ Gaussians. Beyond 3D vision, I also research inference
            acceleration; I recently developed <strong>Early Exit Networks (EENet)</strong> using ResNet backbones to
            optimize computational cost for resource-constrained environments.</p>

        <p>I see a strong connection between my experience in efficient architecture design (EENet) and 3D primitives
            (3DGS) and your lab’s focus on efficient perception (Lp-3DGS, MFNeRF). I would love to contribute to this
            intersection as a research intern in your lab for Summer 2025.</p>

        <p>I have attached my resume and linked my portfolio below. Thank you for your time and pioneering work in
            efficient vision.</p>

        <p>Best regards,<br>
            Rishit Saxena<br>
            <a href="https://rishitsaxena55.github.io">Portfolio</a> | <a
                href="https://github.com/RishitSaxena55">GitHub</a>
        </p>
    </div>
</body>

</html>
